# Development Roadmap

## Current Sprint
- [x] Implement AWQ quantization using AutoAWQ
- [x] Update requirements.txt with necessary dependencies
- [ ] Test the updated quantization process with various models
- [ ] Implement model validation after quantization
- [ ] Add option to specify output bit-width (2-bit, 3-bit, 4-bit, 8-bit)
- [ ] Update documentation with new quantization details and usage instructions

## Backlog
- [ ] Optimize model loading process for large models
- [ ] Implement progress tracking for long-running operations
- [ ] Move configuration to YAML or JSON file
- [ ] Implement support for additional quantization methods
- [ ] Add support for model checksum validation
- [ ] Improve documentation with more examples and use cases

## Completed
- [x] Fix model downloading issue in model_utils.py
- [x] Improve error handling and logging for the download process
- [x] Expand test coverage
- [x] Enhance error handling and logging across all modules
- [x] Improve user feedback and progress indication
- [x] Restore organized folder structure for output files
- [x] Ensure complete processing of all model files
