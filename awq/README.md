# Quant-AWQ Application

The Quant-AWQ Application automates the quantization of models using the Adaptive Weight Quantization (AWQ) method, providing efficient and fast lower-bit model representations suitable for production environments.

## Features

- **Automated Model Quantization**: Converts models to lower-bit representations using AWQ techniques.
- **Support for Multiple Model Formats**: Handles PyTorch models and converts them to `safetensors` format.
- **Template-based Documentation Management**: Automatically updates README files using predefined templates.
- **Robust Logging and Error Handling**: Offers comprehensive logging and error handling throughout the quantization process.

## Prerequisites

- Python 3.8 or newer
- CUDA-compatible GPU (for GPU acceleration)

## Installation

1. Clone the repository:
   ```bash
   git clone https://github.com/your-repo/quant-awq.git
   cd quant-awq
   ```

2. Install dependencies:
   ```bash
   pip install -r requirements.txt
   ```

## Usage

### Basic Usage

Run the application with the following command from the root directory of the project:

```bash
python app/main.py --author [author] --model [model]
```

Replace `[author]` and `[model]` with the actual author and model name you wish to quantize.

## Detailed Usage

1. Prepare your model:
   Ensure your model is in a supported format (PyTorch .bin or .pt files).

2. Set up configuration:
   Modify the `app/config.py` file to set your desired quantization parameters.

3. Run the quantization:
   ```bash
   python app/main.py --author [author_name] --model [model_name]
   ```
   Replace `[author_name]` and `[model_name]` with the appropriate values.

4. Check the output:
   The quantized model will be saved in the `data/` directory with the suffix "-AWQ".

## Configuration

Modify the settings in `app/config.py` to adjust paths, quantization parameters, and other operational settings as needed.

## Project Structure

- `app/`: Contains the main application code.
  - `config.py`: Configuration settings for the application.
  - `converter.py`: Manages the conversion of models from PyTorch to `safetensors`.
  - `main.py`: Entry point of the application.
  - `model_utils.py`: Utilities for managing model downloads and preprocessing.
  - `quantization.py`: Core logic for model quantization.
  - `template_parser.py`: Handles the updating of README files from templates.
- `data/`: Directory for storing model data and outputs.
- `logs/`: Contains log files generated by the application.
- `repos/`: Stores configuration files and scripts used in the quantization process.
- `tests/`: Unit tests for the application's functionality.

## Testing

Run the unit tests to verify that all components of the application are functioning correctly:

```bash
python run_tests.py
```

## Contributing

Contributions to the project are welcome. Please fork the repository, make your changes, and submit a pull request.

## License

This project is licensed under the MIT License - see the LICENSE.md file for details.

